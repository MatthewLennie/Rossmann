look at GPU usage ->   watch -d -n 0.5 nvidia-smi 
Things to check 
- how does fastAI do the embedding layers. 
- LR Finder
- Is batch norm implemented as it is intended to be 
- validation set in eval mode to avoid drop out. 
- is faster with memory async

Hyperparameters to include 
- Batch size
- Embedding sizes 
- depth
- layer sizes
- Momentum
